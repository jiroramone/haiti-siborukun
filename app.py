import streamlit as st
import pandas as pd
import numpy as np
import re
import plotly.express as px

# --- 1. åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="é…ç½®é¦¬åˆ¸è¡“ Web", layout="wide")

def to_half_width(text):
    if pd.isna(text): return text
    text = str(text)
    table = str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼', '0123456789.')
    return re.sub(r'[^\d\.]', '', text.translate(table))

def normalize_name(x):
    if pd.isna(x): return ''
    # è¨˜å·ï¼ˆ$ * â–² â–³ â˜† â˜…ï¼‰ã‚’ã™ã¹ã¦é™¤å»ã—ã¦ç´”ç²‹ãªåå‰ã«ã™ã‚‹
    return re.sub(r'[â˜…â˜†â–²â–³â—‡$*â˜…â˜†â–²â–³â—‡]', '', str(x).strip().replace('ã€€', '').replace(' ', ''))

# --- 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆ12/27å½¢å¼å¯¾å¿œï¼‰ ---
@st.cache_data
def load_data(file):
    try:
        if file.name.endswith('.xlsx'):
            df = pd.read_excel(file, engine='openpyxl')
        else:
            try: df = pd.read_csv(file, encoding='utf-8')
            except: df = pd.read_csv(file, encoding='cp932')
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ä½ç½®è‡ªå‹•ç‰¹å®š
        if not any(col in str(df.columns) for col in ['é¦¬', 'ç•ª', 'R', 'é¨']):
            for i in range(min(len(df), 10)):
                if any(x in str(df.iloc[i].values) for x in ['é¦¬', 'ç•ª', 'R']):
                    df.columns = df.iloc[i]; df = df.iloc[i+1:].reset_index(drop=True); break

        df.columns = df.columns.astype(str).str.strip()
        name_map = {
            'å ´æ‰€': 'å ´å', 'é–‹å‚¬': 'å ´å', 'ç«¶é¦¬å ´': 'å ´å',
            'èª¿æ•™å¸«': 'å©èˆ', 'èª¿æ•™å¸«å': 'å©èˆ', 'å©èˆå': 'å©èˆ',
            'é¨æ‰‹å': 'é¨æ‰‹', 'ãƒ¬ãƒ¼ã‚¹': 'R', 'ï¼²': 'R', 'ç•ª': 'æ­£ç•ª', 'é¦¬ç•ª': 'æ­£ç•ª',
            'å˜ã‚ªãƒƒã‚º': 'å˜ï½µï½¯ï½½ï¾', 'å˜å‹ã‚ªãƒƒã‚º': 'å˜ï½µï½¯ï½½ï¾', 'ã‚ªãƒƒã‚º': 'å˜ï½µï½¯ï½½ï¾',
            'æ­£å¾ª': 'æ­£å¾ªç’°', 'é€†å¾ª': 'é€†å¾ªç’°'
        }
        df = df.rename(columns=name_map)
        
        # å¿…é ˆåˆ—ç¢ºä¿
        ensure_cols = ['R', 'å ´å', 'é¦¬å', 'æ­£ç•ª', 'é¨æ‰‹', 'å©èˆ', 'é¦¬ä¸»', 'å˜ï½µï½¯ï½½ï¾', 'ç€é †']
        for col in ensure_cols:
            if col not in df.columns: df[col] = np.nan

        # æ•°å€¤åŒ–
        df['R'] = pd.to_numeric(df['R'].apply(to_half_width), errors='coerce')
        df['æ­£ç•ª'] = pd.to_numeric(df['æ­£ç•ª'].apply(to_half_width), errors='coerce')
        df = df.dropna(subset=['R', 'æ­£ç•ª'])
        df['R'] = df['R'].astype(int); df['æ­£ç•ª'] = df['æ­£ç•ª'].astype(int)

        for col in ['é¨æ‰‹', 'å©èˆ', 'é¦¬ä¸»', 'é¦¬å', 'å ´å']:
            df[col] = df[col].apply(normalize_name)
        
        df['å˜ï½µï½¯ï½½ï¾'] = pd.to_numeric(df['å˜ï½µï½¯ï½½ï¾'].apply(to_half_width), errors='coerce')
        
        return df.copy(), "success"
    except Exception as e: return pd.DataFrame(), str(e)

# --- 3. é…ç½®è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ (å…¨ãƒ¬ãƒ¼ã‚¹å…±é€šãƒ­ã‚¸ãƒƒã‚¯) ---
def analyze_haichi(df):
    df = df.copy()
    max_umaban = df.groupby(['å ´å', 'R'])['æ­£ç•ª'].transform('max')
    if 'é€†ç•ª' not in df.columns or df['é€†ç•ª'].isna().all():
        df['é€†ç•ª'] = (max_umaban + 1) - df['æ­£ç•ª']
    if 'æ­£å¾ªç’°' not in df.columns or df['æ­£å¾ªç’°'].isna().all():
        df['æ­£å¾ªç’°'] = max_umaban + df['æ­£ç•ª']
    if 'é€†å¾ªç’°' not in df.columns or df['é€†å¾ªç’°'].isna().all():
        df['é€†å¾ªç’°'] = max_umaban + df['é€†ç•ª']

    for c in ['æ­£ç•ª', 'é€†ç•ª', 'æ­£å¾ªç’°', 'é€†å¾ªç’°']:
        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)

    df['ã‚¿ã‚¤ãƒ—_list'] = [[] for _ in range(len(df))]
    df['ãƒ‘ã‚¿ãƒ¼ãƒ³_list'] = [[] for _ in range(len(df))]
    df['æ¡ä»¶_list'] = [[] for _ in range(len(df))]
    df['ã‚¹ã‚³ã‚¢'] = 0.0

    idx_map = {(row['å ´å'], row['R'], row['æ­£ç•ª']): idx for idx, row in df.iterrows()}

    # A. é’å¡— (å…¨éå…±é€šå€¤)
    blue_info = []
    for col in ['é¨æ‰‹', 'å©èˆ', 'é¦¬ä¸»']:
        group_keys = ['å ´å', col] if col == 'é¨æ‰‹' else [col]
        for name, group in df.groupby(group_keys):
            if len(group) < 2 or not name: continue
            all_sets = [{r['æ­£ç•ª'], r['é€†ç•ª'], r['æ­£å¾ªç’°'], r['é€†å¾ªç’°']} for _, r in group.iterrows()]
            common = set.intersection(*all_sets)
            if common:
                priority = 1.0 if col == 'é¨æ‰‹' else 0.2
                val_str = ','.join(map(str, sorted(list(common))))
                for _, row in group.iterrows():
                    idx = idx_map.get((row['å ´å'], row['R'], row['æ­£ç•ª']))
                    if idx is not None:
                        df.at[idx, 'ã‚¿ã‚¤ãƒ—_list'].append(f'â˜…{col}é’å¡—')
                        df.at[idx, 'ãƒ‘ã‚¿ãƒ¼ãƒ³_list'].append('é’å¡—')
                        df.at[idx, 'æ¡ä»¶_list'].append(f'å…¨å…±é€š({val_str})')
                        df.at[idx, 'ã‚¹ã‚³ã‚¢'] += 9.0 + priority
                        blue_info.append({'å ´å':row['å ´å'], 'R':row['R'], 'æ­£ç•ª':row['æ­£ç•ª'], 'å±æ€§':f"{col}:{name}", 'å˜ï½µï½¯ï½½ï¾':row['å˜ï½µï½¯ï½½ï¾']})

    # B. é’å¡—ã®éš£
    for b in blue_info:
        for t_num in [b['æ­£ç•ª']-1, b['æ­£ç•ª']+1]:
            key = (b['å ´å'], b['R'], t_num)
            if key in idx_map:
                idx = idx_map[key]; n_score = 9.0; is_rev = False
                if pd.notna(b['å˜ï½µï½¯ï½½ï¾']) and pd.notna(df.at[idx, 'å˜ï½µï½¯ï½½ï¾']):
                    if df.at[idx, 'å˜ï½µï½¯ï½½ï¾'] < b['å˜ï½µï½¯ï½½ï¾']: n_score += 2.0; is_rev = True
                if not any('é’å¡—éš£' in x for x in df.at[idx, 'ã‚¿ã‚¤ãƒ—_list']):
                    df.at[idx, 'ã‚¿ã‚¤ãƒ—_list'].append('â–³é’å¡—éš£' + ('(é€†è»¢)' if is_rev else ''))
                    df.at[idx, 'ãƒ‘ã‚¿ãƒ¼ãƒ³_list'].append('é’éš£')
                    df.at[idx, 'æ¡ä»¶_list'].append(f"#{b['æ­£ç•ª']}ã®éš£")
                    df.at[idx, 'ã‚¹ã‚³ã‚¢'] += n_score

    # C. ãƒšã‚¢åˆ†æ (16ãƒ‘ã‚¿ãƒ¼ãƒ³)
    pair_labels = list("ABCDEFGHIJKLMNOP")
    for col in ['é¨æ‰‹', 'å©èˆ', 'é¦¬ä¸»']:
        for name, group in df.groupby(['å ´å', col] if col=='é¨æ‰‹' else col):
            if len(group) < 2 or not name: continue
            rows = group.sort_values('R').to_dict('records')
            for i in range(len(rows)-1):
                r1, r2 = rows[i], rows[i+1]
                v1 = [r1[c] for c in ['æ­£ç•ª', 'é€†ç•ª', 'æ­£å¾ªç’°', 'é€†å¾ªç’°']]
                v2 = [r2[c] for c in ['æ­£ç•ª', 'é€†ç•ª', 'æ­£å¾ªç’°', 'é€†å¾ªç’°']]
                pats = [pair_labels[x*4+y] for x in range(4) for y in range(4) if v1[x]==v2[y] and v1[x]!=0]
                if pats:
                    p_str = "".join(pats); is_c = any(x in pats for x in ['C','D','G','H'])
                    for r_data, partner_R in [(r1, r2['R']), (r2, r1['R'])]:
                        idx = idx_map.get((r_data['å ´å'], r_data['R'], r_data['æ­£ç•ª']))
                        if idx is not None:
                            df.at[idx, 'ã‚¿ã‚¤ãƒ—_list'].append('â—ãƒãƒ£ãƒ³ã‚¹' if is_c else 'â—‹ç‹™ã„ç›®')
                            df.at[idx, 'ãƒ‘ã‚¿ãƒ¼ãƒ³_list'].append(p_str)
                            df.at[idx, 'æ¡ä»¶_list'].append(f"ãƒšã‚¢({partner_R}R)")
                            df.at[idx, 'ã‚¹ã‚³ã‚¢'] += 4.0 if is_c else 3.0

    df['ã‚¿ã‚¤ãƒ—'] = df['ã‚¿ã‚¤ãƒ—_list'].apply(lambda x: ' / '.join(x))
    df['ãƒ‘ã‚¿ãƒ¼ãƒ³'] = df['ãƒ‘ã‚¿ãƒ¼ãƒ³_list'].apply(lambda x: ','.join(x))
    df['æ¡ä»¶'] = df['æ¡ä»¶_list'].apply(lambda x: ' '.join(x))
    return df

# --- 4. åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ---
def apply_ranking_logic(df_in):
    if df_in.empty: return df_in
    df = df_in.copy()
    df['ç€é †'] = pd.to_numeric(df['ç€é †'], errors='coerce')
    hit_patterns = set()
    if not df[df['ç€é †'] <= 3].empty:
        p_str = ','.join(df[df['ç€é †']<=3]['ãƒ‘ã‚¿ãƒ¼ãƒ³'].dropna().astype(str))
        hit_patterns = set(p_str.replace(',', '').split()) # 1æ–‡å­—ãšã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        if not hit_patterns: # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®å ´åˆ
             hit_patterns = set(','.join(df[df['ç€é †']<=3]['ãƒ‘ã‚¿ãƒ¼ãƒ³'].dropna().astype(str)).split(','))

    def get_rec(row):
        score = row.get('ã‚¹ã‚³ã‚¢', 0); odds = pd.to_numeric(row.get('å˜ï½µï½¯ï½½ï¾'), errors='coerce')
        pats = str(row.get('ãƒ‘ã‚¿ãƒ¼ãƒ³', '')).split(',')
        bonus = 4.0 if any(p in hit_patterns and len(p)==1 for p in pats) else 0.0
        if odds > 49.9: bonus -= 30.0
        total = score + bonus
        row['ç·åˆã‚¹ã‚³ã‚¢'] = total # ä¿å­˜
        if total >= 15: return "ğŸ‘‘ ç›¤çŸ³ã®è»¸"
        if total >= 12: return "âœ¨ æ¨å¥¨è»¸"
        if total >= 10: return "ğŸ”¥ æ¿€ç†±ç›¸æ‰‹"
        return "â–² é’å¡—ç©´" if 'é’' in str(row['ã‚¿ã‚¤ãƒ—']) else "â–³ ç´"

    df['æ¨å¥¨è²·ã„ç›®'] = df.apply(get_rec, axis=1)
    # ç·åˆã‚¹ã‚³ã‚¢ã‚’åæ˜ 
    df['å‚¾å‘åŠ ç‚¹'] = df.apply(lambda r: 4.0 if any(p in hit_patterns and len(p)==1 for p in str(r['ãƒ‘ã‚¿ãƒ¼ãƒ³']).split(',')) else 0.0, axis=1)
    df['ç·åˆã‚¹ã‚³ã‚¢'] = df['ã‚¹ã‚³ã‚¢'] + df['å‚¾å‘åŠ ç‚¹']
    return df

# --- 5. UI ---
st.title("ğŸ‡ é…ç½®é¦¬åˆ¸è¡“ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ")

with st.sidebar:
    up_file = st.file_uploader("ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['xlsx', 'csv'])
    if 'analyzed_df' in st.session_state:
        st.download_button("ğŸ’¾ ä¿å­˜", st.session_state['analyzed_df'].to_csv(index=False).encode('utf-8-sig'), "race_result.csv")

if up_file:
    df_raw, status = load_data(up_file)
    if status == "success":
        if 'analyzed_df' not in st.session_state:
            st.session_state['analyzed_df'] = apply_ranking_logic(analyze_haichi(df_raw))
        
        # --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¾©æ´»: é›†è¨ˆMetrics ---
        current_df = st.session_state['analyzed_df']
        df_hits = current_df[current_df['ç€é †'].notna()].copy()
        df_fuku = df_hits[df_hits['ç€é †'] <= 3]
        
        st.subheader("ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ")
        c1, c2, c3 = st.columns(3)
        with c1: st.metric("æ¶ˆåŒ–ãƒ¬ãƒ¼ã‚¹", len(df_hits['R'].unique()))
        with c2: 
            rate = len(df_fuku)/len(df_hits)*100 if len(df_hits)>0 else 0
            st.metric("æ¨å¥¨é¦¬ è¤‡å‹ç‡", f"{rate:.1f}%")
        with c3: st.metric("çš„ä¸­æ•°", f"{len(df_fuku)} é ­")

        # --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¾©æ´»: çµæœå…¥åŠ› & è¡¨ç¤º ---
        full_df = st.session_state['analyzed_df']
        places = sorted(full_df['å ´å'].unique())
        
        with st.form("result_form"):
            p_tabs = st.tabs(places)
            edited_dfs = []
            for p_tab, place in zip(p_tabs, places):
                with p_tab:
                    p_df = full_df[full_df['å ´å'] == place]
                    r_tabs = st.tabs([f"{r}R" for r in sorted(p_df['R'].unique())])
                    for r_tab, r_num in zip(r_tabs, sorted(p_df['R'].unique())):
                        with r_tab:
                            disp = p_df[p_df['R'] == r_num].sort_values('æ­£ç•ª')
                            # æ¨å¥¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                            top = disp.sort_values('ç·åˆã‚¹ã‚³ã‚¢', ascending=False).iloc[0]
                            if top['ç·åˆã‚¹ã‚³ã‚¢'] >= 12:
                                st.info(f"ğŸ’¡ {r_num}R æ¨å¥¨: {top['æ­£ç•ª']} {top['é¦¬å']} ({top['æ¨å¥¨è²·ã„ç›®']})")
                            
                            ed = st.data_editor(disp, disabled=[c for c in disp.columns if c != 'ç€é †'], hide_index=True, use_container_width=True, key=f"ed_{place}_{r_num}")
                            edited_dfs.append(ed)
            if st.form_submit_button("ğŸ”„ å…¥åŠ›ã‚’ç¢ºå®šã—ã¦å†è¨ˆç®—"):
                combined = pd.concat(edited_dfs, ignore_index=True)
                st.session_state['analyzed_df'] = apply_ranking_logic(combined)
                st.rerun()

        # --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¾©æ´»: å††ã‚°ãƒ©ãƒ• ---
        if not df_fuku.empty:
            st.divider()
            col_g1, col_g2 = st.columns([1, 1])
            with col_g1:
                all_p = []
                for p in df_fuku['ãƒ‘ã‚¿ãƒ¼ãƒ³']:
                    if p: all_p.extend(str(p).split(','))
                if all_p:
                    fig = px.pie(pd.Series(all_p).value_counts().reset_index(), values='count', names='index', title='çš„ä¸­ãƒ‘ã‚¿ãƒ¼ãƒ³å†…è¨³', hole=0.4)
                    st.plotly_chart(fig, use_container_width=True)
            with col_g2:
                st.write("**çš„ä¸­é¦¬ä¸€è¦§**")
                st.dataframe(df_fuku[['å ´å', 'R', 'æ­£ç•ª', 'é¦¬å', 'ã‚¿ã‚¤ãƒ—', 'ç€é †']], hide_index=True)
